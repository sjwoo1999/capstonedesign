import 'dart:async';
import 'dart:convert';
import 'dart:typed_data';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:record/record.dart';
import 'dart:io';
import 'package:path_provider/path_provider.dart';

/// ì˜¤ë””ì˜¤ ê´€ë¦¬ì - ë§ˆì´í¬ ì¶©ëŒ ë°©ì§€
class AudioManager {
  static final AudioManager _instance = AudioManager._internal();
  factory AudioManager() => _instance;
  AudioManager._internal();

  // STT ê´€ë ¨
  late stt.SpeechToText _speech;
  bool _isListening = false;
  
  // ë…¹ìŒ ê´€ë ¨
  final Record _audioRecorder = Record();
  bool _isRecording = false;
  String? _currentRecordingPath;
  DateTime? _recordingStartTime;
  
  // ìƒíƒœ ê´€ë¦¬
  bool _isInitialized = false;
  StreamController<double>? _soundLevelController;
  
  // ì½œë°± í•¨ìˆ˜ë“¤
  Function(String)? onTextRecognized;
  Function(double)? onSoundLevelChanged;
  Function(String)? onError;
  Function(String)? onStatusChanged;
  
  /// í˜„ì¬ ë…¹ìŒ ì¤‘ì¸ì§€ í™•ì¸
  bool get isRecording => _isRecording;

  /// ì´ˆê¸°í™”
  Future<bool> initialize({
    Function(String)? onTextRecognized,
    Function(double)? onSoundLevelChanged,
    Function(String)? onError,
    Function(String)? onStatusChanged,
  }) async {
    if (_isInitialized) return true;
    
    this.onTextRecognized = onTextRecognized;
    this.onSoundLevelChanged = onSoundLevelChanged;
    this.onError = onError;
    this.onStatusChanged = onStatusChanged;
    
    try {
      // STT ì´ˆê¸°í™”
      _speech = stt.SpeechToText();
      final available = await _speech.initialize(
        onError: (error) {
          print('ğŸ¤ [AudioManager] STT ì—ëŸ¬: ${error.errorMsg}');
          // error_no_matchëŠ” ì •ìƒì ì¸ ìƒí™©ì´ë¯€ë¡œ ì—ëŸ¬ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
          if (!error.errorMsg.contains('no_match')) {
            onError?.call('STT Error: ${error.errorMsg}');
          } else {
            print('â„¹ï¸ [AudioManager] ìŒì„± ì¸ì‹ ì—†ìŒ (ì •ìƒì ì¸ ìƒí™©)');
          }
        },
        onStatus: (status) {
          print('STT Status: $status');
          onStatusChanged?.call(status);
        },
      );
      
      if (!available) {
        onError?.call('STT ì‚¬ìš© ë¶ˆê°€');
        return false;
      }
      
      // ì˜¤ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”
      final hasPermission = await _audioRecorder.hasPermission();
      if (!hasPermission) {
        onError?.call('ë§ˆì´í¬ ê¶Œí•œ ì—†ìŒ');
        return false;
      }
      
      _isInitialized = true;
      print('âœ… AudioManager ì´ˆê¸°í™” ì„±ê³µ');
      return true;
      
    } catch (e) {
      onError?.call('ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
      return false;
    }
  }

  /// ì˜¤ë””ì˜¤ ê¶Œí•œ í™•ì¸
  Future<bool> _checkPermissions() async {
    try {
      final hasPermission = await _audioRecorder.hasPermission();
      print('ğŸ” [AudioManager] ì˜¤ë””ì˜¤ ê¶Œí•œ ìƒíƒœ: $hasPermission');
      return hasPermission;
    } catch (e) {
      print('âŒ [AudioManager] ê¶Œí•œ í™•ì¸ ì‹¤íŒ¨: $e');
      return false;
    }
  }

  /// ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘
  Future<void> startRecording() async {
    try {
      print('ğŸ¤ [AudioManager] ë…¹ìŒ ì‹œì‘ ì‹œë„');
      
      if (_isRecording) {
        print('âš ï¸ [AudioManager] ì´ë¯¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤');
        return;
      }

      // ê¶Œí•œ í™•ì¸
      final hasPermission = await _checkPermissions();
      if (!hasPermission) {
        print('âŒ [AudioManager] ì˜¤ë””ì˜¤ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤');
        throw Exception('ì˜¤ë””ì˜¤ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤');
      }

      print('âœ… [AudioManager] ì˜¤ë””ì˜¤ ê¶Œí•œ í™•ì¸ ì™„ë£Œ');

      // ë…¹ìŒ íŒŒì¼ ê²½ë¡œ ì„¤ì •
      final directory = await getTemporaryDirectory();
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      _currentRecordingPath = '${directory.path}/audio_$timestamp.m4a';
      
      print('ğŸ“ [AudioManager] ë…¹ìŒ íŒŒì¼ ê²½ë¡œ: $_currentRecordingPath');

      // ë…¹ìŒ ì„¤ì • - STTì™€ ì¶©ëŒí•˜ì§€ ì•Šë„ë¡ ë³„ë„ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
      final recorder = Record();
      
      // ë…¹ìŒ ì‹œì‘
      await recorder.start(
        path: _currentRecordingPath,
        encoder: AudioEncoder.aacLc,
        bitRate: 128000,
        samplingRate: 44100,
        numChannels: 2,
      );

      _isRecording = true;
      _recordingStartTime = DateTime.now();
      
      print('âœ… [AudioManager] ë…¹ìŒ ì‹œì‘ ì™„ë£Œ');
      print('ğŸ“Š [AudioManager] ë…¹ìŒ ì„¤ì •:');
      print('   - ì¸ì½”ë”: AAC LC');
      print('   - ë¹„íŠ¸ë ˆì´íŠ¸: 128kbps');
      print('   - ìƒ˜í”Œë§ ë ˆì´íŠ¸: 44.1kHz');
      print('   - ì±„ë„: 2 (ìŠ¤í…Œë ˆì˜¤)');
      print('   - ì‹œì‘ ì‹œê°„: $_recordingStartTime');
      print('   - STTì™€ ë™ì‹œ ì‹¤í–‰: ${_isListening ? "ì˜ˆ" : "ì•„ë‹ˆì˜¤"}');

    } catch (e) {
      print('âŒ [AudioManager] ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e');
      _isRecording = false;
      rethrow;
    }
  }

  /// í˜„ì¬ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Base64ë¡œ ë°˜í™˜
  Future<String?> getCurrentAudioData() async {
    try {
      print('ğŸ¤ [AudioManager] í˜„ì¬ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œë„');
      
      if (!_isRecording || _currentRecordingPath == null) {
        print('âš ï¸ [AudioManager] ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆê±°ë‚˜ íŒŒì¼ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤');
        return null;
      }

      // ë…¹ìŒ ì¤‘ì§€ (ì„ì‹œë¡œ)
      await stopRecording();
      print('â¹ï¸ [AudioManager] ë¶„ì„ì„ ìœ„í•´ ë…¹ìŒ ì¼ì‹œ ì¤‘ì§€');

      // íŒŒì¼ ì¡´ì¬ í™•ì¸
      final file = File(_currentRecordingPath!);
      if (!await file.exists()) {
        print('âŒ [AudioManager] ë…¹ìŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: $_currentRecordingPath');
        return null;
      }

      // íŒŒì¼ í¬ê¸° í™•ì¸
      final fileSize = await file.length();
      print('ğŸ“Š [AudioManager] ë…¹ìŒ íŒŒì¼ í¬ê¸°: $fileSize bytes');
      
      if (fileSize < 1000) {
        print('âš ï¸ [AudioManager] ë…¹ìŒ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ (${fileSize} bytes)');
        print('ğŸ’¡ [AudioManager] ìµœì†Œ 1ì´ˆ ì´ìƒ ë…¹ìŒì´ í•„ìš”í•©ë‹ˆë‹¤');
      }

      // íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©
      final bytes = await file.readAsBytes();
      final base64Audio = base64Encode(bytes);
      
      print('âœ… [AudioManager] ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ');
      print('ğŸ“Š [AudioManager] Base64 ë°ì´í„° í¬ê¸°: ${base64Audio.length} bytes');
      print('ğŸ“Š [AudioManager] ë…¹ìŒ ì‹œê°„: ${_recordingStartTime != null ? DateTime.now().difference(_recordingStartTime!).inSeconds : 0}ì´ˆ');

      // ë…¹ìŒ ì¬ì‹œì‘
      await startRecording();
      print('ğŸ”„ [AudioManager] ë¶„ì„ í›„ ë…¹ìŒ ì¬ì‹œì‘');

      return base64Audio;

    } catch (e) {
      print('âŒ [AudioManager] ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: $e');
      return null;
    }
  }

  /// ë…¹ìŒ ì¤‘ì§€
  Future<void> stopRecording() async {
    if (_isRecording) {
      await _audioRecorder.stop();
      _isRecording = false;
      print('ğŸ¤ ë©€í‹°ëª¨ë‹¬ ë…¹ìŒ ì¤‘ì§€');
    }
  }
  
  /// STTë§Œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“œ (VAD ì¶©ëŒ ë°©ì§€)
  Future<bool> startSTTOnly({
    required String localeId,
    Duration listenFor = const Duration(seconds: 30),
    Duration pauseFor = const Duration(seconds: 3),
  }) async {
    if (!_isInitialized) {
      await initialize();
    }
    
    if (_isListening) {
      await stopSTT();
    }
    
    try {
      print('ğŸ¤ [AudioManager] STT ì‹œì‘ ì‹œë„');
      print('ğŸ¤ [AudioManager] ë¡œì¼€ì¼: $localeId');
      print('ğŸ¤ [AudioManager] ì²­ì·¨ ì‹œê°„: ${listenFor.inSeconds}ì´ˆ');
      print('ğŸ¤ [AudioManager] ì¼ì‹œì •ì§€ ì‹œê°„: ${pauseFor.inSeconds}ì´ˆ');
      
      await _speech.listen(
        onResult: (result) {
          print('ğŸ¤ [AudioManager] STT ê²°ê³¼: ${result.recognizedWords} (final: ${result.finalResult})');
          if (result.finalResult) {
            final text = result.recognizedWords.trim();
            if (text.isNotEmpty) {
              print('âœ… [AudioManager] ìµœì¢… í…ìŠ¤íŠ¸ ì¸ì‹: "$text"');
              onTextRecognized?.call(text);
            } else {
              print('âš ï¸ [AudioManager] ë¹ˆ í…ìŠ¤íŠ¸ ê²°ê³¼');
            }
          } else {
            print('ğŸ”„ [AudioManager] ë¶€ë¶„ í…ìŠ¤íŠ¸ ì¸ì‹: "${result.recognizedWords}"');
          }
        },
        listenFor: listenFor,
        pauseFor: pauseFor,
        partialResults: true,
        cancelOnError: false,
        listenMode: stt.ListenMode.dictation,
        localeId: localeId,
        onSoundLevelChange: (level) {
          // VAD ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ì†Œë¦¬ ë ˆë²¨ì€ ë³„ë„ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
          // print('ğŸ¤ [AudioManager] ì†Œë¦¬ ë ˆë²¨: $level');
        },
      );
      
      _isListening = true;
      print('âœ… [AudioManager] STT ì‹œì‘ ì„±ê³µ');
      
      // STT ì„¸ì…˜ ì™„ë£Œ í›„ ìë™ ì¬ì‹œì‘ (ë” ì§§ì€ ê°„ê²©ìœ¼ë¡œ)
      final totalDuration = listenFor + pauseFor + const Duration(seconds: 1);
      print('â° [AudioManager] STT ìë™ ì¬ì‹œì‘ ì˜ˆì•½: ${totalDuration.inSeconds}ì´ˆ í›„');
      
      Timer(totalDuration, () {
        if (_isListening) {
          print('ğŸ”„ [AudioManager] STT ì„¸ì…˜ ì™„ë£Œ, ìë™ ì¬ì‹œì‘');
          startSTTOnly(
            localeId: localeId,
            listenFor: listenFor,
            pauseFor: pauseFor,
          );
        } else {
          print('â¹ï¸ [AudioManager] STTê°€ ì¤‘ì§€ë¨, ìë™ ì¬ì‹œì‘ ì·¨ì†Œ');
        }
      });
      
      return true;
      
    } catch (e) {
      print('âŒ [AudioManager] STT ì‹œì‘ ì‹¤íŒ¨: $e');
      onError?.call('STT ì‹œì‘ ì‹¤íŒ¨: $e');
      return false;
    }
  }
  
  /// STT ì‹œì‘ (í•œêµ­ì–´)
  Future<bool> startSTT() async {
    return await startSTTOnly(
      localeId: 'ko_KR',
      listenFor: const Duration(seconds: 30),
      pauseFor: const Duration(seconds: 3),
    );
  }
  
  /// ë…ë¦½ì ì¸ VAD ëª¨ë“œ (STTì™€ ë¶„ë¦¬)
  Future<bool> startIndependentVAD() async {
    if (!_isInitialized) {
      await initialize();
    }
    
    if (_isRecording) {
      await stopVAD();
    }
    
    try {
      _soundLevelController = StreamController<double>();
      
      // ë…ë¦½ì ì¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ VAD ì²˜ë¦¬
      await _audioRecorder.start(
        encoder: AudioEncoder.aacLc,
        bitRate: 128000,
        samplingRate: 44100,
      );
      
      _isRecording = true;
      
      // ì£¼ê¸°ì ìœ¼ë¡œ ì†Œë¦¬ ë ˆë²¨ ì¸¡ì •
      Timer.periodic(const Duration(milliseconds: 100), (timer) async {
        if (!_isRecording) {
          timer.cancel();
          return;
        }
        
        try {
          final amplitude = await _audioRecorder.getAmplitude();
          final level = _convertAmplitudeToDb(amplitude.current);
          onSoundLevelChanged?.call(level);
        } catch (e) {
          // VAD ì—ëŸ¬ëŠ” ë¬´ì‹œ (STTì— ì˜í–¥ ì—†ìŒ)
        }
      });
      
      return true;
      
    } catch (e) {
      onError?.call('VAD ì‹œì‘ ì‹¤íŒ¨: $e');
      return false;
    }
  }
  
  /// í…ìŠ¤íŠ¸ ê¸°ë°˜ VAD ì¶”ì •
  double estimateVADFromText(String text) {
    // í…ìŠ¤íŠ¸ ê¸¸ì´, ë‹¨ì–´ ìˆ˜, íŠ¹ìˆ˜ë¬¸ì ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ VAD ì¶”ì •
    final words = text.split(' ').length;
    final length = text.length;
    final hasExclamation = text.contains('!') || text.contains('?');
    final hasEmoji = RegExp(r'[\u{1F600}-\u{1F64F}\u{1F300}-\u{1F5FF}]', unicode: true).hasMatch(text);
    
    // Valence (ê¸ì •ì„±) - ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜
    double valence = 0.5; // ê¸°ë³¸ê°’
    final positiveWords = ['ì¢‹', 'í–‰ë³µ', 'ê¸°ì˜', 'ì¦ê±°', 'ê°ì‚¬', 'ì‚¬ë‘'];
    final negativeWords = ['ë‚˜ì˜', 'ìŠ¬í”„', 'í™”ë‚˜', 'ì§œì¦', 'ë¶ˆë§Œ', 'ì‹«'];
    
    if (positiveWords.any((word) => text.contains(word))) {
      valence = 0.8;
    } else if (negativeWords.any((word) => text.contains(word))) {
      valence = 0.2;
    }
    
    // Arousal (ê°ì„±ë„) - í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ íŠ¹ìˆ˜ë¬¸ì ê¸°ë°˜
    double arousal = 0.5;
    if (hasExclamation || hasEmoji) {
      arousal = 0.8;
    } else if (length < 10) {
      arousal = 0.3;
    }
    
    // Dominance (ì§€ë°°ì„±) - ë‹¨ì–´ ìˆ˜ ê¸°ë°˜
    double dominance = 0.5;
    if (words > 10) {
      dominance = 0.8; // ê¸´ ë¬¸ì¥ = ë†’ì€ ì§€ë°°ì„±
    } else if (words < 3) {
      dominance = 0.3; // ì§§ì€ ë¬¸ì¥ = ë‚®ì€ ì§€ë°°ì„±
    }
    
    return (valence + arousal + dominance) / 3; // í‰ê· ê°’ ë°˜í™˜
  }
  
  /// STT ì¤‘ì§€
  Future<void> stopSTT() async {
    if (_isListening) {
      await _speech.stop();
      _isListening = false;
    }
  }
  
  /// VAD ì¤‘ì§€
  Future<void> stopVAD() async {
    if (_isRecording) {
      await _audioRecorder.stop();
      _isRecording = false;
      _soundLevelController?.close();
      _soundLevelController = null;
    }
  }
  
  /// ëª¨ë“  ì˜¤ë””ì˜¤ ì¤‘ì§€
  Future<void> stopAll() async {
    await stopSTT();
    await stopVAD();
    await stopRecording();
  }
  
  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    stopAll();
    _audioRecorder.dispose();
  }
  
  /// ì§„í­ì„ ë°ì‹œë²¨ë¡œ ë³€í™˜
  double _convertAmplitudeToDb(double amplitude) {
    if (amplitude <= 0) return -60.0;
    return 20 * log(amplitude / 32767) / ln10;
  }
  
  // ìˆ˜í•™ í•¨ìˆ˜ë“¤
  static const double ln10 = 2.302585092994046;
  double log(double x) => x <= 0 ? 0 : x.log();
}

// double í™•ì¥ ë©”ì„œë“œ
extension DoubleExtension on double {
  double log() => this <= 0 ? 0 : this.log();
} 