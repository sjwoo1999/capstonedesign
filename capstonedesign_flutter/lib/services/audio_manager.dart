import 'dart:async';
import 'dart:convert';
import 'dart:typed_data';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:record/record.dart';
import 'dart:io';

/// ì˜¤ë””ì˜¤ ê´€ë¦¬ì - ë§ˆì´í¬ ì¶©ëŒ ë°©ì§€
class AudioManager {
  static final AudioManager _instance = AudioManager._internal();
  factory AudioManager() => _instance;
  AudioManager._internal();

  // STT ê´€ë ¨
  late stt.SpeechToText _speech;
  bool _isListening = false;
  
  // ë…¹ìŒ ê´€ë ¨
  final Record _audioRecorder = Record();
  bool _isRecording = false;
  String? _currentRecordingPath;
  
  // ìƒíƒœ ê´€ë¦¬
  bool _isInitialized = false;
  StreamController<double>? _soundLevelController;
  
  // ì½œë°± í•¨ìˆ˜ë“¤
  Function(String)? onTextRecognized;
  Function(double)? onSoundLevelChanged;
  Function(String)? onError;
  Function(String)? onStatusChanged;
  
  /// í˜„ì¬ ë…¹ìŒ ì¤‘ì¸ì§€ í™•ì¸
  bool get isRecording => _isRecording;

  /// ì´ˆê¸°í™”
  Future<bool> initialize({
    Function(String)? onTextRecognized,
    Function(double)? onSoundLevelChanged,
    Function(String)? onError,
    Function(String)? onStatusChanged,
  }) async {
    if (_isInitialized) return true;
    
    this.onTextRecognized = onTextRecognized;
    this.onSoundLevelChanged = onSoundLevelChanged;
    this.onError = onError;
    this.onStatusChanged = onStatusChanged;
    
    try {
      // STT ì´ˆê¸°í™”
      _speech = stt.SpeechToText();
      final available = await _speech.initialize(
        onError: (error) {
          onError?.call('STT Error: ${error.errorMsg}');
        },
        onStatus: (status) {
          print('STT Status: $status');
          onStatusChanged?.call(status);
        },
      );
      
      if (!available) {
        onError?.call('STT ì‚¬ìš© ë¶ˆê°€');
        return false;
      }
      
      // ì˜¤ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”
      final hasPermission = await _audioRecorder.hasPermission();
      if (!hasPermission) {
        onError?.call('ë§ˆì´í¬ ê¶Œí•œ ì—†ìŒ');
        return false;
      }
      
      _isInitialized = true;
      print('âœ… AudioManager ì´ˆê¸°í™” ì„±ê³µ');
      return true;
      
    } catch (e) {
      onError?.call('ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
      return false;
    }
  }

  /// ë©€í‹°ëª¨ë‹¬ ë¶„ì„ì„ ìœ„í•œ ë…¹ìŒ ì‹œì‘
  Future<bool> startRecording() async {
    if (!_isInitialized) {
      await initialize();
    }
    
    if (_isRecording) {
      await stopRecording();
    }
    
    try {
      // ì„ì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±
      final tempDir = Directory.systemTemp;
      _currentRecordingPath = '${tempDir.path}/audio_${DateTime.now().millisecondsSinceEpoch}.m4a';
      
      // ë…¹ìŒ ì‹œì‘
      await _audioRecorder.start(
        path: _currentRecordingPath,
        encoder: AudioEncoder.aacLc,
        bitRate: 128000,
        samplingRate: 44100,
      );
      
      _isRecording = true;
      print('ğŸ¤ ë©€í‹°ëª¨ë‹¬ ë…¹ìŒ ì‹œì‘: $_currentRecordingPath');
      
      return true;
      
    } catch (e) {
      onError?.call('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e');
      return false;
    }
  }

  /// í˜„ì¬ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ base64ë¡œ ë°˜í™˜
  Future<String?> getCurrentAudioData() async {
    if (!_isRecording || _currentRecordingPath == null) {
      return null;
    }
    
    try {
      // í˜„ì¬ ë…¹ìŒ ì¤‘ì¸ íŒŒì¼ ì½ê¸°
      final file = File(_currentRecordingPath!);
      if (await file.exists()) {
        final bytes = await file.readAsBytes();
        final base64Data = base64Encode(bytes);
        print('ğŸ¤ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘: ${base64Data.length} bytes');
        return base64Data;
      }
    } catch (e) {
      print('âŒ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: $e');
    }
    
    return null;
  }

  /// ë…¹ìŒ ì¤‘ì§€
  Future<void> stopRecording() async {
    if (_isRecording) {
      await _audioRecorder.stop();
      _isRecording = false;
      print('ğŸ¤ ë©€í‹°ëª¨ë‹¬ ë…¹ìŒ ì¤‘ì§€');
    }
  }
  
  /// STTë§Œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“œ (VAD ì¶©ëŒ ë°©ì§€)
  Future<bool> startSTTOnly({
    required String localeId,
    Duration listenFor = const Duration(seconds: 30),
    Duration pauseFor = const Duration(seconds: 3),
  }) async {
    if (!_isInitialized) {
      await initialize();
    }
    
    if (_isListening) {
      await stopSTT();
    }
    
    try {
      await _speech.listen(
        onResult: (result) {
          if (result.finalResult) {
            final text = result.recognizedWords.trim();
            if (text.isNotEmpty) {
              onTextRecognized?.call(text);
            }
          }
        },
        listenFor: listenFor,
        pauseFor: pauseFor,
        partialResults: true,
        cancelOnError: false,
        listenMode: stt.ListenMode.dictation,
        localeId: localeId,
        // onSoundLevelChange ì œê±° - VAD ì¶©ëŒ ë°©ì§€
      );
      
      _isListening = true;
      return true;
      
    } catch (e) {
      onError?.call('STT ì‹œì‘ ì‹¤íŒ¨: $e');
      return false;
    }
  }
  
  /// STT ì‹œì‘ (í•œêµ­ì–´)
  Future<bool> startSTT() async {
    return await startSTTOnly(
      localeId: 'ko_KR',
      listenFor: const Duration(seconds: 30),
      pauseFor: const Duration(seconds: 3),
    );
  }
  
  /// ë…ë¦½ì ì¸ VAD ëª¨ë“œ (STTì™€ ë¶„ë¦¬)
  Future<bool> startIndependentVAD() async {
    if (!_isInitialized) {
      await initialize();
    }
    
    if (_isRecording) {
      await stopVAD();
    }
    
    try {
      _soundLevelController = StreamController<double>();
      
      // ë…ë¦½ì ì¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ VAD ì²˜ë¦¬
      await _audioRecorder.start(
        encoder: AudioEncoder.aacLc,
        bitRate: 128000,
        samplingRate: 44100,
      );
      
      _isRecording = true;
      
      // ì£¼ê¸°ì ìœ¼ë¡œ ì†Œë¦¬ ë ˆë²¨ ì¸¡ì •
      Timer.periodic(const Duration(milliseconds: 100), (timer) async {
        if (!_isRecording) {
          timer.cancel();
          return;
        }
        
        try {
          final amplitude = await _audioRecorder.getAmplitude();
          final level = _convertAmplitudeToDb(amplitude.current);
          onSoundLevelChanged?.call(level);
        } catch (e) {
          // VAD ì—ëŸ¬ëŠ” ë¬´ì‹œ (STTì— ì˜í–¥ ì—†ìŒ)
        }
      });
      
      return true;
      
    } catch (e) {
      onError?.call('VAD ì‹œì‘ ì‹¤íŒ¨: $e');
      return false;
    }
  }
  
  /// í…ìŠ¤íŠ¸ ê¸°ë°˜ VAD ì¶”ì •
  double estimateVADFromText(String text) {
    // í…ìŠ¤íŠ¸ ê¸¸ì´, ë‹¨ì–´ ìˆ˜, íŠ¹ìˆ˜ë¬¸ì ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ VAD ì¶”ì •
    final words = text.split(' ').length;
    final length = text.length;
    final hasExclamation = text.contains('!') || text.contains('?');
    final hasEmoji = RegExp(r'[\u{1F600}-\u{1F64F}\u{1F300}-\u{1F5FF}]', unicode: true).hasMatch(text);
    
    // Valence (ê¸ì •ì„±) - ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜
    double valence = 0.5; // ê¸°ë³¸ê°’
    final positiveWords = ['ì¢‹', 'í–‰ë³µ', 'ê¸°ì˜', 'ì¦ê±°', 'ê°ì‚¬', 'ì‚¬ë‘'];
    final negativeWords = ['ë‚˜ì˜', 'ìŠ¬í”„', 'í™”ë‚˜', 'ì§œì¦', 'ë¶ˆë§Œ', 'ì‹«'];
    
    if (positiveWords.any((word) => text.contains(word))) {
      valence = 0.8;
    } else if (negativeWords.any((word) => text.contains(word))) {
      valence = 0.2;
    }
    
    // Arousal (ê°ì„±ë„) - í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ íŠ¹ìˆ˜ë¬¸ì ê¸°ë°˜
    double arousal = 0.5;
    if (hasExclamation || hasEmoji) {
      arousal = 0.8;
    } else if (length < 10) {
      arousal = 0.3;
    }
    
    // Dominance (ì§€ë°°ì„±) - ë‹¨ì–´ ìˆ˜ ê¸°ë°˜
    double dominance = 0.5;
    if (words > 10) {
      dominance = 0.8; // ê¸´ ë¬¸ì¥ = ë†’ì€ ì§€ë°°ì„±
    } else if (words < 3) {
      dominance = 0.3; // ì§§ì€ ë¬¸ì¥ = ë‚®ì€ ì§€ë°°ì„±
    }
    
    return (valence + arousal + dominance) / 3; // í‰ê· ê°’ ë°˜í™˜
  }
  
  /// STT ì¤‘ì§€
  Future<void> stopSTT() async {
    if (_isListening) {
      await _speech.stop();
      _isListening = false;
    }
  }
  
  /// VAD ì¤‘ì§€
  Future<void> stopVAD() async {
    if (_isRecording) {
      await _audioRecorder.stop();
      _isRecording = false;
      _soundLevelController?.close();
      _soundLevelController = null;
    }
  }
  
  /// ëª¨ë“  ì˜¤ë””ì˜¤ ì¤‘ì§€
  Future<void> stopAll() async {
    await stopSTT();
    await stopVAD();
    await stopRecording();
  }
  
  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    stopAll();
    _audioRecorder.dispose();
  }
  
  /// ì§„í­ì„ ë°ì‹œë²¨ë¡œ ë³€í™˜
  double _convertAmplitudeToDb(double amplitude) {
    if (amplitude <= 0) return -60.0;
    return 20 * log(amplitude / 32767) / ln10;
  }
  
  // ìˆ˜í•™ í•¨ìˆ˜ë“¤
  static const double ln10 = 2.302585092994046;
  double log(double x) => x <= 0 ? 0 : x.log();
}

// double í™•ì¥ ë©”ì„œë“œ
extension DoubleExtension on double {
  double log() => this <= 0 ? 0 : this.log();
} 